![alt text](logo/logoMadridJUG.png) Madrid Java User Group (Madrid JUG)


Handwritten Digit Recognition (CLASSIFICATION PROBLEM)
========================================================
This is a classification problem (machine learning)

  Dataset ZipCode (Dimensions)
  http://www-stat.stanford.edu/~tibs/ElemStatLearn/datasets/zip.info

Normalized handwritten digits, automatically scanned from envelopes by 
the U.S. Postal Service. The original scanned digits are binary and 
of different sizes and orientations; the images here have been deslanted 
and size normalized, resulting in 16 x 16 grayscale images (Le Cun et al., 1990).

The data are in two gzipped files, and each line consists of the digit id (0-9) followed 
by the 256 grayscale values.

  001 002 003 004 ... 015 016  
  017 018 019 020 ... 031 032   
  033 034 035 036 ... 037 038   
   |   |   |   |  ...  |   |  
  209 210 211 212 ... 223 224   
  225 226 227 228 ... 239 240   
  241 242 243 244 ... 255 256   
******
#### May 9, 2013
#### Jose Maria Gomez Hidalgo [@jmgomez](http://twitter.com/jmgomez)
#### Guillermo Santos Garcia [@gsantosgo](http://twitter.com/gsantosgo)
#### This script is licensed under the GPLv2 license http://www.gnu.org/licenses/gpl.html
----------------------------------------------------------------

## Preliminaries
### Set Working Directory
```{r working directory}
getwd()
WORKING_DIR <- "~/R/RStats/MadridJUG-DataMining/" 
#WORKING_DIR <- "C:/Users/gsantos/R/RStats/MadridJUG-DataMining"
DATASET_DIR <- "./data/"
FIGURES_DIR <- "./figures/"
COLORS <- c('white','black')
setwd(WORKING_DIR)
getwd()
```

### Load libraries/data/create new variables

```{r loadData}
### Load Libraries 
#install.packages(c("knitr","RColorBrewer","ElemStatLearn","foreign","tree""RWeka","rpart","maptree","e1071")) 
library(knitr) # Markdown 
library(RColorBrewer) 
library(ElemStatLearn) 
library(foreign) # For reading and writing data stored by statistical packages such as Minitab,S,SAS,SPSS
library(tree)
library(maptree) 
library(rpart) # Recursive Partitioning and Regression Trees (RPart)
library(RWeka) # Weka 
library(FNN) # Fast k-Nearest Neighbors (kNN)
library(e1071) # Support Vector Machine (SVM) 

### Set Color
# colorRampPalette(COLORS) ( 4 ) ## (n)
CUSTOM_COLORS <- colorRampPalette(colors=COLORS)
CUSTOM_COLORS_PLOT <- colorRampPalette(brewer.pal(10,"Set3"))
# Figures Label
opts_chunk$set(fig.path='figures/plot-handwritten')
#opts_chunk$set(echo=FALSE, fig.path='figures/plot-hw-', cache=TRUE)

### Load data
DATASET.train <- as.data.frame(zip.train)
DATASET.test <- as.data.frame(zip.test)
```

------

## Exploratory analysis

### Look at the TRAINING data set 

```{r, dependson="loadData"}
head(DATASET.train)
dim(DATASET.train)
nrow(DATASET.train)
ncol(DATASET.train)
colnames(DATASET.train)
summary(DATASET.train)
sapply(DATASET.train[1,], class)
```

### Look at the TEST data set 

```{r, dependson="loadData"}
head(DATASET.test)
dim(DATASET.test)
nrow(DATASET.test)
ncol(DATASET.test)
colnames(DATASET.test)
summary(DATASET.test)
sapply(DATASET.test[1,], class)
```

### Find number of missing values/check ranges (TRAINING data set)

```{r, dependson="loadData"}
sum(is.na(DATASET.train))
```

### Find number of missing values/check ranges (TESTING data set)

```{r, dependson="loadData"}
sum(is.na(DATASET.test))
```

### Transformation. Transform Label as Factor (Categorical) and Change Column Names (TRAINING data set)
```{r, dependson="loadData"}
DATASET.train[,1] <- as.factor(DATASET.train[,1]) # As Category
colnames(DATASET.train) <- c("Y",paste("X.",1:256,sep=""))
class(DATASET.train[,1])
levels(DATASET.train[,1])
sapply(DATASET.train[1,], class)
```

### Transformation. Transform Label as Factor (Categorical) and Change Column Names (TESTING data set)
```{r, dependson="loadData"}
DATASET.test[,1] <- as.factor(DATASET.test[,1]) # As Category
colnames(DATASET.test) <- c("Y",paste("X.",1:256,sep=""))
class(DATASET.test[,1])
levels(DATASET.test[,1])
sapply(DATASET.test[1,], class)
```

### Write data set in Weka Attribute-Relation File Format (ARFF) files.
```{r, dependson="loadData"}
#write.arff(DATASET.train, paste0(DATASET_DIR,"zip.train.arff"))
#write.arff(DATASET.test, paste0(DATASET_DIR,"zip.test.arff"))
```


### Display digits of training data set (An average of each digits)

More info http://www.r-bloggers.com/the-essence-of-a-handwritten-digit/
```{r, dependson="loadData"}
par(mfrow=c(4,3),pty='s',mar=c(1,1,1,1),xaxt='n',yaxt='n')
images_digits_0_9 <- array(dim=c(10,16*16))
for(digit in 0:9)
{
  print(digit)
  images_digits_0_9[digit+1,] <- apply(DATASET.train[DATASET.train[,1]==digit,-1],2,sum)
  images_digits_0_9[digit+1,] <- images_digits_0_9[digit+1,]/max(images_digits_0_9[digit+1,])*255
  z <- array(images_digits_0_9[digit+1,], dim=c(16,16))
  z <- z[,16:1] ##right side up
  image(1:16,1:16,z,main=digit,col=CUSTOM_COLORS(256))
}
```


### Generating PDF file with digits of Training Data Set 
```{r, dependson="loadData"}
#pdf(file=paste0(FIGURES_DIR,"trainDigit.pdf"),)
par(mfrow=c(4,4),pty='s',mar=c(3,3,3,3),xaxt='n',yaxt='n')
for(i in 1:10)
{
  z <- array(as.vector(as.matrix(DATASET.train[i,-1])),dim=c(16,16))
  z <- z[,16:1] ##right side up
  image(1:16,1:16,z,main=DATASET.train[i,1],col=CUSTOM_COLORS(256))
  print(i)
}
```

### Total Number of Digits (Training Set)
```{r, dependson="loadData"}
resTable <- table(DATASET.train$Y)
par(mfrow=c(1,1))
par(mar=c(5, 4, 4, 2) + 0.1) # increase y-axis margin.
plot <- plot(DATASET.train$Y,col=CUSTOM_COLORS_PLOT(10), main="Total Number of Digits (Training Set)", ylim=c(0,1500), ylab="Examples Number")
text(x=plot,y=resTable+50, labels=resTable, cex=0.75)
par(mfrow=c(1,1))
percentage <- round(resTable/sum(resTable)*100)
labels <- paste0 (row.names(resTable), " (", percentage ,"%) ") # add percents to labels
pie(resTable, labels=labels,col=CUSTOM_COLORS_PLOT(10),main="Total Number of Digits (Training Set)")
```


### Total Number of Digits (Testing Set)
```{r, dependson="loadData"}
resTable <- table(DATASET.test$Y)
par(mfrow=c(1,1))
par(mar=c(5, 4, 4, 2) + 0.1) # increase y-axis margin.
plot <- plot(DATASET.test$Y,col=CUSTOM_COLORS_PLOT(10), main="Total Number of Digits (Testing Set)", ylim=c(0,400), ylab="Examples Number")
text(x=plot,y=resTable+20, labels=resTable, cex=0.75)
par(mfrow=c(1,1))
percentage <- round(resTable/sum(resTable)*100)
labels <- paste0 (row.names(resTable), " (", percentage ,"%) ") # add percents to labels
pie(resTable, labels=labels,col=CUSTOM_COLORS_PLOT(10),main="Total Number of Digits (Testing Set)")
```

------

## Classification. Predictive Model. RPart (Recursive Partitioning and Regression Trees) Algorithm 

```{r model_rpart, dependson="loadData"}
pc <- proc.time()
model.rpart <- rpart(DATASET.train$Y ~ . ,method="class", data=DATASET.train)
proc.time() - pc
printcp(model.rpart)

plot(model.rpart, uniform=TRUE, main="Classification (RPART). Tree of Handwritten Digit Recognition ")
text(model.rpart, all=TRUE ,cex=.75)
draw.tree(model.rpart, cex=0.5, nodeinfo=TRUE, col=gray(0:8 / 8))
```

### Confusion Matrix (RPart)
```{r dependson="model_rpart"}
prediction.rpart <- predict(model.rpart, newdata=DATASET.test, type='class')
table("Actual Class"=DATASET.test$Y, "Predicted Class"=prediction.rpart)
error.rate.rpart <- sum(DATASET.test$Y != prediction.rpart) / nrow(DATASET.test)
print (paste0("Accuary (Precision): ", 1 - error.rate.rpart))
```

### Predict Digit for Example 1 (RPart)
```{r dependson="model_rpart"}
row <- 1
prediction.digit <- as.vector(predict(model.rpart, newdata=DATASET.test[row,],type='class'))
print (paste0("Current Digit: ", as.character(DATASET.test$Y[row])))
print (paste0("Predicted Digit: ", prediction.digit))     
z <- array(as.vector(as.matrix(DATASET.test[row,-1])),dim=c(16,16))
z <- z[,16:1] ##right side up
par(mfrow=c(1,3),pty='s',mar=c(1,1,1,1),xaxt='n',yaxt='n')
image(1:16,1:16,z,main=DATASET.test[row,1],col=CUSTOM_COLORS(256))
```

------

## Classification. k-Nearest Neighbors (kNN) Algorithm 

```{r model_knn, dependson="loadData"}
pc <- proc.time()
model.knn <- IBk(DATASET.train$Y ~ . , data=DATASET.train)
proc.time() - pc
summary(model.knn)
```

### Confusion Matrix (kNN)
```{r dependson="model_knn"}
prediction.knn <- predict(model.knn, newdata=DATASET.test, type='class')
table("Actual Class"=DATASET.test$Y, "Predicted Class"=prediction.knn)
error.rate.knn <- sum(DATASET.test$Y != prediction.knn) / nrow(DATASET.test)
print (paste0("Accuary (Precision): ", 1 - error.rate.knn))
```

### Predict Digit for Example 1 (kNN)
```{r dependson="model_knn"}
row <- 1
prediction.digit <- as.vector(predict(model.knn, newdata=DATASET.test[row,],type='class'))
print (paste0("Current Digit: ", as.character(DATASET.test$Y[row])))
print (paste0("Predicted Digit: ", prediction.digit))     
par(mfrow=c(1,3),pty='s',mar=c(1,1,1,1),xaxt='n',yaxt='n')
z <- array(as.vector(as.matrix(DATASET.test[row,-1])),dim=c(16,16))
z <- z[,16:1] ##right side up
image(1:16,1:16,z,main=DATASET.test[row,1],col=CUSTOM_COLORS(256))
```

------

## Classification. Fast Nearest Neighbors (FNN) Algorithm 

```{r model_fnn, dependson="loadData"}
pc <- proc.time()
# Avoid Name Collision (knn)
model.fnn <- FNN::knn(DATASET.train[,-1], DATASET.test[, -1], DATASET.train$Y, k = 10, algorithm="cover_tree")
proc.time() - pc
summary(model.fnn)
```

### Confusion Matrix (FNN)
```{r dependson="model_fnn"}
table("Actual Class"=DATASET.test$Y, "Predicted Class"=model.fnn)
error.rate.fnn <- sum(DATASET.test$Y != model.fnn) / nrow(DATASET.test)
print (paste0("Accuary (Precision): ", 1 - error.rate.fnn))
```

### Predict Digit for Example 1 (FNN)
```{r dependson="model_fnn"}
row <- 1
prediction.digit <- model.fnn[row]  
print (paste0("Current Digit: ", as.character(DATASET.test$Y[row])))
print (paste0("Predicted Digit: ", prediction.digit))     
par(mfrow=c(1,3),pty='s',mar=c(1,1,1,1),xaxt='n',yaxt='n')
z <- array(as.vector(as.matrix(DATASET.test[row,-1])),dim=c(16,16))
z <- z[,16:1] ##right side up
image(1:16,1:16,z,main=DATASET.test[row,1],col=CUSTOM_COLORS(256))
```

------

## Classification. Predictive Model. Naive Bayes Algorithm 
```{r model_naiveBayes, dependson="loadData"}
pc <- proc.time()
model.naiveBayes <- naiveBayes(DATASET.train$Y ~ . , data=DATASET.train)
proc.time() - pc
summary(model.naiveBayes)
```

### Confusion Matrix (naiveBayes)
```{r dependson="model_naiveBayes"}
prediction.naiveBayes <- predict(model.naiveBayes, newdata=DATASET.test, type='class')
table("Actual Class"=DATASET.test$Y, "Predicted Class"=prediction.naiveBayes)
error.rate.naiveBayes <- sum(DATASET.test$Y != prediction.naiveBayes) / nrow(DATASET.test)
print (paste0("Accuary (Precision): ", 1 - error.rate.naiveBayes))
```

### Predict Digit for Example 1 (naiveBayes)
```{r dependson="model_naiveBayes"}
#All Prediction for Row 1 
row <- 1
prediction.digit <- as.vector(predict(model.naiveBayes, newdata=DATASET.test[row,], type='class'))     
print (paste0("Current Digit: ", as.character(DATASET.test$Y[row])))
print (paste0("Predicted Digit: ", prediction.digit))     
z <- array(as.vector(as.matrix(DATASET.test[row,-1])),dim=c(16,16))
z <- z[,16:1] ##right side up
par(mfrow=c(1,3),pty='s',mar=c(1,1,1,1),xaxt='n',yaxt='n')
image(1:16,1:16,z,main=DATASET.test[row,1],col=CUSTOM_COLORS(256))
```

------

## Classification. Predictive Model. SVM (Support Vector Machine) Algorithm 
```{r model_svm, dependson="loadData"}
pc <- proc.time()
model.svm <- svm(DATASET.train$Y ~ . ,method="class", data=DATASET.train)
proc.time() - pc
summary(model.svm)
#plot(model.svm, DATASET.train, DATASET.train$Y ~z )
```

### Confusion Matrix (SVM)
```{r dependson="model_svm"}
prediction.svm <- predict(model.svm, newdata=DATASET.test, type='class')
table("Actual Class"=DATASET.test$Y, "Predicted Class"=prediction.svm)
error.rate.svm <- sum(DATASET.test$Y != prediction.svm) / nrow(DATASET.test)
print (paste0("Accuary (Precision): ", 1 - error.rate.svm))
```

### Predict Digit for Example 1 (SVM)
```{r dependson="model_svm"}
#All Prediction for Row 1 
row <- 1
prediction.digit <- as.vector(predict(model.svm, newdata=DATASET.test[row,], type='class'))     
print (paste0("Current Digit: ", as.character(DATASET.test$Y[row])))
print (paste0("Predicted Digit: ", prediction.digit))     
z <- array(as.vector(as.matrix(DATASET.test[row,-1])),dim=c(16,16))
z <- z[,16:1] ##right side up
par(mfrow=c(1,3),pty='s',mar=c(1,1,1,1),xaxt='n',yaxt='n')
image(1:16,1:16,z,main=DATASET.test[row,1],col=CUSTOM_COLORS(256))
```

### Errors with Support Vector Machine (SVM)
```{r dependson="model_svm"}
errors <- as.vector(which(DATASET.test$Y != prediction.svm))
print(paste0("Error Numbers: ",length(errors)))
predicted <- as.vector(prediction.svm)
par(mfrow=c(4,4), pty='s', mar=c(3,3,3,3), xaxt='n', yaxt='n')
for(i in 1:length(errors))
{
  z <- array(as.vector(as.matrix(DATASET.test[errors[i],-1])),dim=c(16,16))
  z <- z[,16:1] ##right side up  
  image(1:16,1:16,z,
          main=paste0("C.D.:", as.character(DATASET.test$Y[i]), " - Pr.D.:", predicted[errors[i]]),col=CUSTOM_COLORS(256))  
}
```
